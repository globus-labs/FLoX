{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Pytorch Tutorial\n",
    "\n",
    "In this tutorial, you will see how to use flox to run FL experiments on PyTorch using first a local executor and then using real physical endpoints. We will train our model to classify instances from the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import Tensor\n",
    "\n",
    "from flox.clients.PyTorchClient import PyTorchClient\n",
    "from flox.controllers.PyTorchController import PyTorchController\n",
    "from flox.model_trainers.PyTorchTrainer import PyTorchTrainer\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data\n",
    "\n",
    "Firstly, let's get some test data so we can evaluate our model later on. The function below takes in a dictionary with varibles that specify the dataset, batch_size, etc., and returns a train and test ``torch.utils.data.DataLoader`` instance that we will use for testing our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:47<00:00, 3586962.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def get_test_data(config):\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    batch_size = config.get(\"batch_size\", 32)\n",
    "    dataset_name = config[\"dataset_name\"]\n",
    "    num_workers = config.get(\"num_workers\", 8)\n",
    "    root = config.get(\"data_root\", \"./data\")\n",
    "\n",
    "    # create train DataLoader\n",
    "    trainset = dataset_name(root=root, train=True, download=True, transform=transform)\n",
    "\n",
    "    train_split_len = (\n",
    "        len(trainset) if \"num_samples\" not in config.keys() else config[\"num_samples\"]\n",
    "    )\n",
    "\n",
    "    train_subpart = torch.utils.data.random_split(\n",
    "        trainset, [train_split_len, len(trainset) - train_split_len]\n",
    "    )[0]\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subpart, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # create test DataLoader\n",
    "    testset = dataset_name(root=root, train=False, download=True, transform=transform)\n",
    "    test_split_len = (\n",
    "        len(trainset) if \"num_samples\" not in config.keys() else config[\"num_samples\"]\n",
    "    )\n",
    "\n",
    "    test_subpart = torch.utils.data.random_split(\n",
    "        testset, [test_split_len, len(testset) - test_split_len]\n",
    "    )[0]\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_subpart, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "data_config = {\n",
    "    \"num_samples\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "    \"dataset_name\": torchvision.datasets.CIFAR10,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "_, testloader = get_test_data(data_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model\n",
    "\n",
    "Now, let's define our PyTorch model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        import torch\n",
    "\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating Model Trainer and Client instances\n",
    "\n",
    "Next, we will initialize an instance of a PyTorch Model Trainer and Client. You can check out their implementation under ``flox/model_trainers`` and ``flox/clients``, respectively. You can also extend or modify these classes to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_trainer = PyTorchTrainer(net)\n",
    "torch_client = PyTorchClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the Controller (Local Execution)\n",
    "\n",
    "Let's also define our endpoints and initialize the PyTorch *Controller* that will do the heavy lifting of deploying tasks to the endpoints. We will run three rounds of FL, with 100 samples and 1 training epoch on each device. Note that we are specifying ``executor_type`` to \"local\", which will use ``concurrent.futures.ThreadPoolExecutor`` to execute the tasks locally. We are also providing the dataset name and the test data. Finally, we'll launch the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676522661.787290 2023-02-16 12:44:21 INFO MainProcess-18532 MainThread-11664 __main__:3 <module> Endpoints: ['simulated_endpoint_1', 'simulated_endpoint_2', 'simulated_endpoint_3']\n",
      "1676522661.788293 2023-02-16 12:44:21 INFO MainProcess-18532 MainThread-11664 __main__:18 <module> STARTING FL TORCH FLOW...\n",
      "1676522661.790294 2023-02-16 12:44:21 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:166 on_model_init No executor was provided, trying to retrieve the provided executor type local from the list of available executors: {'local': <class 'concurrent.futures.thread.ThreadPoolExecutor'>, 'funcx': <class 'funcx.sdk.executor.FuncXExecutor'>}\n",
      "1676522661.792294 2023-02-16 12:44:21 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:170 on_model_init The selected executor is <class 'concurrent.futures.thread.ThreadPoolExecutor'>\n",
      "1676522663.218177 2023-02-16 12:44:23 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:209 on_model_broadcast Launching the <class 'concurrent.futures.thread.ThreadPoolExecutor'> executor\n",
      "1676522663.220225 2023-02-16 12:44:23 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:215 on_model_broadcast Starting to broadcast a task to endpoint simulated_endpoint_1\n",
      "1676522681.543199 2023-02-16 12:44:41 WARNING MainProcess-18532 MainThread-11664 flox.controllers.MainController:220 on_model_broadcast Could not check the status of the endpoint simulated_endpoint_1, the error is: ('GET', 'https://api2.funcx.org/v2/endpoints/simulated_endpoint_1/status', 'Bearer', 500, 'UNKNOWN_ERROR', 'An unknown or unhandled error occurred.')\n",
      "1676522681.547185 2023-02-16 12:44:41 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:247 on_model_broadcast Deployed the task to endpoint simulated_endpoint_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676522707.808488 2023-02-16 12:45:07 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:290 on_model_receive Starting to retrieve results from endpoints\n",
      "1676522707.809497 2023-02-16 12:45:07 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:305 on_model_receive Finished retrieving all results from the endpoints\n",
      "c:\\Users\\Nikita\\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:377: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(a)\n",
      "1676522707.813534 2023-02-16 12:45:07 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:335 on_model_aggregate Finished aggregating weights\n",
      "1676522707.815490 2023-02-16 12:45:07 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:398 run_federated_learning Round 0 evaluation results: \n",
      "1676522717.986862 2023-02-16 12:45:17 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:209 on_model_broadcast Launching the <class 'concurrent.futures.thread.ThreadPoolExecutor'> executor\n",
      "1676522717.987861 2023-02-16 12:45:17 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:215 on_model_broadcast Starting to broadcast a task to endpoint simulated_endpoint_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 73.71587228775024, 'metrics': {'accuracy': 0.094}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676522734.669795 2023-02-16 12:45:34 WARNING MainProcess-18532 MainThread-11664 flox.controllers.MainController:220 on_model_broadcast Could not check the status of the endpoint simulated_endpoint_1, the error is: ('GET', 'https://api2.funcx.org/v2/endpoints/simulated_endpoint_1/status', 'Bearer', 500, 'UNKNOWN_ERROR', 'An unknown or unhandled error occurred.')\n",
      "1676522734.670792 2023-02-16 12:45:34 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:247 on_model_broadcast Deployed the task to endpoint simulated_endpoint_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676522764.506683 2023-02-16 12:46:04 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:290 on_model_receive Starting to retrieve results from endpoints\n",
      "1676522764.507685 2023-02-16 12:46:04 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:305 on_model_receive Finished retrieving all results from the endpoints\n",
      "1676522764.508685 2023-02-16 12:46:04 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:335 on_model_aggregate Finished aggregating weights\n",
      "1676522764.510688 2023-02-16 12:46:04 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:398 run_federated_learning Round 1 evaluation results: \n",
      "1676522774.168290 2023-02-16 12:46:14 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:209 on_model_broadcast Launching the <class 'concurrent.futures.thread.ThreadPoolExecutor'> executor\n",
      "1676522774.169294 2023-02-16 12:46:14 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:215 on_model_broadcast Starting to broadcast a task to endpoint simulated_endpoint_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 73.71451902389526, 'metrics': {'accuracy': 0.094}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676522791.288341 2023-02-16 12:46:31 WARNING MainProcess-18532 MainThread-11664 flox.controllers.MainController:220 on_model_broadcast Could not check the status of the endpoint simulated_endpoint_1, the error is: ('GET', 'https://api2.funcx.org/v2/endpoints/simulated_endpoint_1/status', 'Bearer', 500, 'UNKNOWN_ERROR', 'An unknown or unhandled error occurred.')\n",
      "1676522791.292581 2023-02-16 12:46:31 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:247 on_model_broadcast Deployed the task to endpoint simulated_endpoint_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676522816.476501 2023-02-16 12:46:56 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:290 on_model_receive Starting to retrieve results from endpoints\n",
      "1676522816.477504 2023-02-16 12:46:56 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:305 on_model_receive Finished retrieving all results from the endpoints\n",
      "1676522816.479505 2023-02-16 12:46:56 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:335 on_model_aggregate Finished aggregating weights\n",
      "1676522816.480503 2023-02-16 12:46:56 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:398 run_federated_learning Round 2 evaluation results: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 73.71229720115662, 'metrics': {'accuracy': 0.094}}\n"
     ]
    }
   ],
   "source": [
    "# since we are first executing the experiment locally, it does not matter what we name the endpoints:\n",
    "eps = [\"simulated_endpoint_1\", \"simulated_endpoint_2\", \"simulated_endpoint_3\"]\n",
    "logger.info(f\"Endpoints: {eps}\")\n",
    "\n",
    "flox_controller = PyTorchController(\n",
    "    endpoint_ids=eps,\n",
    "    num_samples=100,\n",
    "    epochs=1,\n",
    "    rounds=3,\n",
    "    client_logic=torch_client,\n",
    "    model_trainer=torch_trainer,\n",
    "    executor_type=\"local\",  # choose \"funcx\" for FuncXExecutor, \"local\" for ThreadPoolExecutor\n",
    "    testloader=testloader,\n",
    "    dataset_name=torchvision.datasets.CIFAR10,\n",
    ")\n",
    "\n",
    "# Finally, let's launch the experiment\n",
    "logger.info(\"STARTING FL LOCAL TORCH FLOW...\")\n",
    "flox_controller.run_federated_learning()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Endpoint (FuncX) Execution \n",
    "\n",
    "Now, let's switch \"endpoint_type\" to \"funcx\" and provide actual endpoints. However, make sure to follow instructions in this directory's README to set up your clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676523188.972713 2023-02-16 12:53:08 INFO MainProcess-18532 MainThread-11664 __main__:2 <module> Endpoints: ['fb93a1c2-a8d7-49f3-ad59-375f4e298784', 'c7487b2b-b129-47e2-989b-5a9ac361befc']\n",
      "1676523188.973714 2023-02-16 12:53:08 INFO MainProcess-18532 MainThread-11664 __main__:17 <module> STARTING FL FUNCX TORCH FLOW...\n",
      "1676523188.975717 2023-02-16 12:53:08 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:166 on_model_init No executor was provided, trying to retrieve the provided executor type funcx from the list of available executors: {'local': <class 'concurrent.futures.thread.ThreadPoolExecutor'>, 'funcx': <class 'funcx.sdk.executor.FuncXExecutor'>}\n",
      "1676523188.976714 2023-02-16 12:53:08 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:170 on_model_init The selected executor is <class 'funcx.sdk.executor.FuncXExecutor'>\n",
      "1676523190.428348 2023-02-16 12:53:10 DEBUG MainProcess-18532 MainThread-11664 flox.controllers.MainController:209 on_model_broadcast Launching the <class 'funcx.sdk.executor.FuncXExecutor'> executor\n",
      "1676523191.886705 2023-02-16 12:53:11 INFO MainProcess-18532 MainThread-11664 flox.controllers.MainController:215 on_model_broadcast Starting to broadcast a task to endpoint fb93a1c2-a8d7-49f3-ad59-375f4e298784\n",
      "1676523192.213147 2023-02-16 12:53:12 WARNING MainProcess-18532 MainThread-11664 flox.controllers.MainController:225 on_model_broadcast Endpoint fb93a1c2-a8d7-49f3-ad59-375f4e298784 is not online, it's offline!\n",
      "1676523192.215092 2023-02-16 12:53:12 ERROR MainProcess-18532 MainThread-11664 flox.controllers.MainController:258 on_model_broadcast The tasks queue is empty, here are the endpoints' statuses: {'fb93a1c2-a8d7-49f3-ad59-375f4e298784': 'offline'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The tasks queue is empty, no tasks were submitted for training!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18532\\1619074072.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Finally, let's launch the experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STARTING FL FUNCX TORCH FLOW...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mflox_controller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_federated_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\nikita\\jupyter_notebooks\\globus_flx_git\\flox\\controllers\\MainController.py\u001b[0m in \u001b[0;36mrun_federated_learning\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;31m# broadcast the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_model_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_average\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikita\\jupyter_notebooks\\globus_flx_git\\flox\\controllers\\MainController.py\u001b[0m in \u001b[0;36mon_model_broadcast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m                 )\n\u001b[0;32m    260\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[1;34mf\"The tasks queue is empty, no tasks were submitted for training!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                 )\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The tasks queue is empty, no tasks were submitted for training!"
     ]
    }
   ],
   "source": [
    "eps = [\"fb93a1c2-a8d7-49f3-ad59-375f4e298784\", \"c7487b2b-b129-47e2-989b-5a9ac361befc\"]\n",
    "logger.info(f\"Endpoints: {eps}\")\n",
    "\n",
    "flox_controller = PyTorchController(\n",
    "    endpoint_ids=eps,\n",
    "    num_samples=100,\n",
    "    epochs=1,\n",
    "    rounds=3,\n",
    "    client_logic=torch_client,\n",
    "    model_trainer=torch_trainer,\n",
    "    executor_type=\"funcx\",  # choose \"funcx\" for FuncXExecutor, \"local\" for ThreadPoolExecutor\n",
    "    testloader=testloader,\n",
    "    dataset_name=torchvision.datasets.CIFAR10,\n",
    ")\n",
    "\n",
    "# Finally, let's launch the experiment\n",
    "logger.info(\"STARTING FL FUNCX TORCH FLOW...\")\n",
    "flox_controller.run_federated_learning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efff6cbb98d358215bff1089158970fa45d4244f79f83d0872f3b03b3a4f531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
