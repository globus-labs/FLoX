{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd3c3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(**kwargs):\n",
    "    return f\"helper_kwargs: {kwargs}\"\n",
    "\n",
    "def train_default_model(model_weights, model_architecture, **kwargs):\n",
    "    return f'DEFAULT model: weights: {model_weights} \\n architecture: {model_architecture}, \\n default_kwargs: {helper(**kwargs)}'\n",
    "\n",
    "def custom_train_model():\n",
    "    return 'Trained CUSTOM model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ba69f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_function(train_model=custom_train_model, data_source='keras'):\n",
    "    \n",
    "    def training_function():\n",
    "        result = train_model()\n",
    "        \n",
    "        if data_source == 'keras':\n",
    "            return f\"{data_source}: {result}\"\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return training_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db4c71de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trained CUSTOM model'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_func = create_training_function(data_source='kek')\n",
    "cust_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "300579c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DEFAULT model: weights: 123 \\n architecture: 456, \\n default_kwargs: helper_kwargs: {'c': 1, 'p': 42}\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_default_model(123, 456, c=1, p=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7c07e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data(num_samples = 100):\n",
    "    from tensorflow import keras\n",
    "    import numpy as np\n",
    "\n",
    "    (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # take a random set of images\n",
    "    idx = np.random.choice(np.arange(len(x_train)), num_samples, replace=True)\n",
    "    x_train = x_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "    return (x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2ed5fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76857d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "endpoint_ids = ['00929e1a-ccc5-40be-8b04-c171f132f7b2', '11983ca1-2d45-40d1-b5a2-8736b3544dea']\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "global_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "global_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# get the model's architecture and weights\n",
    "json_config = global_model.to_json()\n",
    "gm_weights = global_model.get_weights()\n",
    "gm_weights_np = np.asarray(gm_weights, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8dedacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = get_new_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b9fb7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3564 - accuracy: 0.0300\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3094 - accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2366 - accuracy: 0.2100\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2181 - accuracy: 0.2200\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1763 - accuracy: 0.3200\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1382 - accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1167 - accuracy: 0.3400\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0398 - accuracy: 0.4300\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0078 - accuracy: 0.4400\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9414 - accuracy: 0.4700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([[[[-0.00308374, -0.02846969,  0.11923862,  0.1372091 ,\n",
       "                  0.09622682, -0.12552725, -0.00572993,  0.13574612,\n",
       "                  0.11874458,  0.00675087,  0.04690669,  0.03781084,\n",
       "                  0.04851744,  0.13369915,  0.0447103 , -0.00706855,\n",
       "                 -0.05891373,  0.08029041,  0.02478524, -0.06120633,\n",
       "                 -0.12056763, -0.08738794, -0.10197891,  0.09668613,\n",
       "                  0.0984856 ,  0.09276874,  0.11111507,  0.0628399 ,\n",
       "                  0.10185242,  0.09389986, -0.01284155, -0.11243422]],\n",
       "\n",
       "               [[-0.03743424,  0.14415571, -0.02378648, -0.04181101,\n",
       "                  0.03629512,  0.00975019, -0.09322388,  0.05566316,\n",
       "                 -0.05467005, -0.10323391, -0.12276282, -0.14051819,\n",
       "                 -0.05226596, -0.06461635,  0.0919804 , -0.00729473,\n",
       "                 -0.04277572,  0.07424589,  0.1187043 , -0.10935926,\n",
       "                  0.03337073, -0.12946731, -0.0951025 ,  0.13218531,\n",
       "                 -0.10267717,  0.08161136,  0.13690849,  0.02826881,\n",
       "                 -0.1439967 , -0.04787396,  0.05697196, -0.11223513]],\n",
       "\n",
       "               [[-0.00922958,  0.10362461, -0.09452124, -0.01421719,\n",
       "                  0.12228295, -0.04098895,  0.07542317,  0.01371992,\n",
       "                  0.11159678,  0.12292264,  0.14856036,  0.08852945,\n",
       "                  0.03628981, -0.00838749,  0.14510642, -0.02850654,\n",
       "                  0.1268634 , -0.0619576 , -0.1378791 , -0.06205929,\n",
       "                  0.02608404, -0.07693335, -0.14638186,  0.07599898,\n",
       "                 -0.09491731, -0.00541963, -0.05884821, -0.12400691,\n",
       "                 -0.02282544, -0.02233574,  0.12799929,  0.09537837]]],\n",
       "\n",
       "\n",
       "              [[[-0.1061467 ,  0.11305259,  0.00469749,  0.05928037,\n",
       "                 -0.0660524 , -0.07582025,  0.07161444,  0.02185986,\n",
       "                 -0.12691078,  0.00047995, -0.11067039, -0.02276751,\n",
       "                  0.07483848, -0.04315658, -0.10762796,  0.04155689,\n",
       "                 -0.13748682,  0.06016585,  0.0025673 ,  0.08832991,\n",
       "                  0.09023567, -0.08343191, -0.12198471,  0.07872594,\n",
       "                  0.00387361,  0.11579315,  0.11782093, -0.03562904,\n",
       "                  0.10552935, -0.02770737, -0.05242564, -0.03753369]],\n",
       "\n",
       "               [[ 0.00198476,  0.1281263 ,  0.03269126,  0.05295656,\n",
       "                  0.09213743,  0.10705691,  0.14246559, -0.01659663,\n",
       "                  0.11986833,  0.03985685,  0.01564301, -0.12421186,\n",
       "                 -0.02615149,  0.12086036, -0.01553893, -0.09556825,\n",
       "                  0.10050861,  0.11068708, -0.00728527,  0.12431188,\n",
       "                  0.06805632,  0.06282407, -0.12031934,  0.14314356,\n",
       "                 -0.08412905,  0.0025813 , -0.0877634 ,  0.08594115,\n",
       "                 -0.14606829, -0.14702882,  0.09283692, -0.13947181]],\n",
       "\n",
       "               [[ 0.01821507, -0.02787301,  0.14377482,  0.04607368,\n",
       "                  0.13233736,  0.03529069,  0.02388046,  0.05888467,\n",
       "                 -0.11946446,  0.00731012, -0.12068602,  0.13519938,\n",
       "                 -0.08577305,  0.03919698,  0.06843232,  0.12524602,\n",
       "                 -0.14274924,  0.11465895,  0.04096197,  0.00710114,\n",
       "                  0.07025726, -0.05493814,  0.12869361, -0.06947481,\n",
       "                 -0.01627232, -0.05588552,  0.05949251, -0.09239003,\n",
       "                  0.13610321,  0.0526216 , -0.06847011,  0.01620761]]],\n",
       "\n",
       "\n",
       "              [[[ 0.00698257, -0.01742544,  0.14134142,  0.11121126,\n",
       "                  0.01282949,  0.00392168,  0.13179345,  0.04755335,\n",
       "                 -0.11634953,  0.11786263,  0.00199366, -0.04933939,\n",
       "                  0.00272327,  0.11818643,  0.04490104,  0.08338343,\n",
       "                  0.02382073, -0.01378815, -0.14544077,  0.11420294,\n",
       "                  0.14107612, -0.10757208, -0.04154335,  0.06739657,\n",
       "                 -0.08785088,  0.02906153,  0.09855723,  0.00558569,\n",
       "                  0.06234378, -0.11359977, -0.06031315,  0.00724328]],\n",
       "\n",
       "               [[-0.09882308,  0.06331435,  0.07062943,  0.05809831,\n",
       "                  0.04525836,  0.09393265, -0.07400177, -0.00220799,\n",
       "                  0.0056034 ,  0.05603124, -0.04307291, -0.06782308,\n",
       "                 -0.12087212, -0.07326596,  0.01654033, -0.00733438,\n",
       "                 -0.11682177,  0.05064827, -0.1411664 , -0.11269749,\n",
       "                 -0.10990445, -0.09004383, -0.10409318, -0.03129422,\n",
       "                 -0.07991584, -0.02330659,  0.09947071, -0.1088374 ,\n",
       "                 -0.07630166, -0.02089078, -0.05545452,  0.07148891]],\n",
       "\n",
       "               [[ 0.06849308,  0.02251024,  0.03236311,  0.1139534 ,\n",
       "                  0.05148491,  0.04041289,  0.0104056 , -0.07363898,\n",
       "                 -0.08852056,  0.01261074, -0.07072309,  0.0653756 ,\n",
       "                  0.07254495,  0.07583985,  0.09089816, -0.00762893,\n",
       "                 -0.14087266,  0.10649681, -0.0512752 ,  0.10739068,\n",
       "                  0.09557635,  0.12148709, -0.05348847, -0.02728209,\n",
       "                 -0.06225831,  0.02567261, -0.12043525,  0.05558024,\n",
       "                 -0.07635401,  0.08723791,  0.03011708, -0.11103144]]]],\n",
       "             dtype=float32)                                             ,\n",
       "       array([ 7.0011785e-04, -2.9237333e-03, -9.2664559e-04,  2.5650300e-04,\n",
       "               5.5673812e-04, -1.2964217e-03,  9.3644875e-04,  6.5960572e-05,\n",
       "              -3.3699134e-03, -4.4775620e-04, -1.3341780e-03,  2.0246187e-03,\n",
       "              -1.8905757e-03, -2.7539940e-03, -2.6794989e-03, -3.4812912e-03,\n",
       "               5.3536003e-03, -5.7269819e-03, -7.1220086e-03,  6.6270293e-03,\n",
       "               4.1247858e-03,  7.0639784e-03, -8.5428720e-03,  4.5261334e-04,\n",
       "              -6.5832650e-03, -2.5833531e-03, -5.7171322e-03, -2.5459407e-03,\n",
       "              -2.4345476e-04,  3.7613895e-04, -5.1445193e-03, -4.4215946e-03],\n",
       "             dtype=float32)                                                   ,\n",
       "       array([[[[-4.00186516e-02,  6.78007677e-02,  1.35353301e-02, ...,\n",
       "                  7.11523741e-02,  5.14243171e-02,  5.33052012e-02],\n",
       "                [-2.88622696e-02, -4.33226228e-02, -2.79586744e-02, ...,\n",
       "                 -3.31506431e-02, -7.08753690e-02, -2.81198025e-02],\n",
       "                [-4.35254024e-03,  3.93394828e-02,  2.15432849e-02, ...,\n",
       "                 -6.16755262e-02, -1.32792536e-02, -9.31362808e-03],\n",
       "                ...,\n",
       "                [ 5.10092452e-02,  6.14720844e-02, -4.88127582e-04, ...,\n",
       "                 -3.92787866e-02,  3.77911367e-02,  6.17632382e-02],\n",
       "                [ 1.18209468e-02,  4.64622639e-02,  6.92238957e-02, ...,\n",
       "                 -2.85324324e-02,  3.96100320e-02, -2.02494692e-02],\n",
       "                [ 3.74500826e-02,  6.89082080e-03,  3.63210738e-02, ...,\n",
       "                  6.76908195e-02,  5.49340546e-02,  4.94884923e-02]],\n",
       "\n",
       "               [[-3.50261070e-02, -5.37487045e-02, -7.95942247e-02, ...,\n",
       "                 -2.43009999e-02,  3.36474776e-02, -7.92463794e-02],\n",
       "                [-6.82769939e-02, -4.89143888e-03,  5.82663305e-02, ...,\n",
       "                  1.15575520e-02, -4.71292324e-02, -5.81504628e-02],\n",
       "                [ 7.85946175e-02, -1.59527622e-02,  1.26370052e-02, ...,\n",
       "                  5.11829183e-02,  6.70338050e-03,  5.05001396e-02],\n",
       "                ...,\n",
       "                [ 8.06616321e-02,  4.56496477e-02,  2.37445831e-02, ...,\n",
       "                 -6.37953803e-02, -4.49489318e-02,  2.41897237e-02],\n",
       "                [-7.65421689e-02,  4.58947942e-02,  3.51267532e-02, ...,\n",
       "                  2.08516587e-02, -6.54351413e-02, -1.91992279e-02],\n",
       "                [-1.67554989e-02, -5.15384823e-02, -7.18608275e-02, ...,\n",
       "                  5.85897006e-02,  1.26721933e-02, -5.02614565e-02]],\n",
       "\n",
       "               [[ 2.33707000e-02,  2.24990230e-02, -6.25679940e-02, ...,\n",
       "                  2.91021429e-02, -5.37983291e-02, -3.89157757e-02],\n",
       "                [ 5.39619401e-02, -7.27607831e-02, -4.29300964e-02, ...,\n",
       "                  1.69592537e-02, -4.02927026e-02, -1.12813823e-02],\n",
       "                [ 8.24394748e-02,  4.04348448e-02,  4.82228063e-02, ...,\n",
       "                  5.81173040e-03, -8.37031868e-04, -1.47080179e-02],\n",
       "                ...,\n",
       "                [-2.26401314e-02, -3.31723206e-02, -1.35603230e-02, ...,\n",
       "                  2.21113525e-02, -7.27472678e-02,  4.91894083e-03],\n",
       "                [ 6.68461919e-02,  5.94094954e-02, -5.68675324e-02, ...,\n",
       "                  7.69286826e-02,  1.78193580e-02,  1.88285131e-02],\n",
       "                [ 2.16105022e-02,  5.71164526e-02, -1.44963348e-02, ...,\n",
       "                  4.71499935e-02,  3.13074403e-02, -3.04672532e-02]]],\n",
       "\n",
       "\n",
       "              [[[-3.91067006e-02,  2.65987776e-02, -1.74621623e-02, ...,\n",
       "                 -2.79060174e-02, -7.29863122e-02,  1.24659101e-02],\n",
       "                [-6.73670173e-02, -7.96688795e-02, -3.76409292e-02, ...,\n",
       "                 -1.43151719e-03, -1.92768220e-03,  2.43067387e-02],\n",
       "                [-2.84284018e-02, -3.06613501e-02,  5.00321761e-02, ...,\n",
       "                 -7.86849484e-02, -4.61953282e-02,  9.43734217e-03],\n",
       "                ...,\n",
       "                [ 5.49268946e-02, -5.86548895e-02, -2.69011653e-04, ...,\n",
       "                 -1.72736701e-02,  4.84355502e-02, -2.07006894e-02],\n",
       "                [-8.32427666e-03, -3.91382203e-02,  4.74150479e-02, ...,\n",
       "                 -5.47592435e-03, -3.31626497e-02, -4.24511172e-02],\n",
       "                [-3.12858187e-02,  7.16338009e-02, -4.91145477e-02, ...,\n",
       "                 -7.96986818e-02,  8.76137149e-03,  6.52782321e-02]],\n",
       "\n",
       "               [[ 8.63310322e-02, -6.89746216e-02,  8.08051974e-02, ...,\n",
       "                  1.40474532e-02, -3.04191280e-02,  6.54749870e-02],\n",
       "                [ 2.95075607e-02, -7.88576305e-02,  6.19278178e-02, ...,\n",
       "                 -8.70486498e-02,  9.32788651e-04,  3.86255272e-02],\n",
       "                [ 2.87124375e-03,  5.55289201e-02, -4.20082873e-03, ...,\n",
       "                 -1.54952414e-03,  8.10289569e-03,  4.18136194e-02],\n",
       "                ...,\n",
       "                [ 6.77361637e-02, -1.17369797e-02, -5.61545752e-02, ...,\n",
       "                  4.20856215e-02,  3.65921063e-03, -2.68754605e-02],\n",
       "                [-1.77246926e-03, -6.62105307e-02, -7.88019449e-02, ...,\n",
       "                  5.03598973e-02,  3.98484059e-02, -5.40691949e-02],\n",
       "                [ 5.42576797e-03, -3.02969553e-02, -4.40735184e-02, ...,\n",
       "                  3.15868929e-02,  1.80077683e-02, -7.70663694e-02]],\n",
       "\n",
       "               [[-8.28110948e-02,  2.58210618e-02, -4.26967032e-02, ...,\n",
       "                  4.20458280e-02, -7.15760738e-02, -8.22547674e-02],\n",
       "                [ 2.72977185e-02,  4.76427423e-03, -1.92866642e-02, ...,\n",
       "                 -4.95482087e-02, -3.52901593e-02,  6.49903342e-02],\n",
       "                [-1.18895071e-02,  1.81619432e-02,  8.03536251e-02, ...,\n",
       "                  5.02136461e-02,  1.29124438e-02,  1.45536195e-02],\n",
       "                ...,\n",
       "                [-7.72267208e-03,  2.10393593e-02,  5.87805314e-03, ...,\n",
       "                  3.10553657e-03,  7.45544136e-02, -6.19374588e-03],\n",
       "                [ 6.01320863e-02, -3.98411080e-02,  3.50042060e-02, ...,\n",
       "                  8.36661905e-02, -4.65343855e-02,  6.75592646e-02],\n",
       "                [ 7.41131976e-02,  1.08163245e-02,  7.81802908e-02, ...,\n",
       "                 -3.32186930e-02, -3.44870146e-04,  5.61382584e-02]]],\n",
       "\n",
       "\n",
       "              [[[-2.32606139e-02,  7.72332773e-02,  1.78391580e-02, ...,\n",
       "                 -3.59974019e-02, -3.26164253e-02,  6.07073121e-02],\n",
       "                [ 3.36216018e-02, -3.33994773e-04, -6.73402846e-02, ...,\n",
       "                 -4.60739508e-02, -2.27227267e-02,  6.79075439e-03],\n",
       "                [ 9.03119445e-02,  5.49576022e-02,  7.38417357e-02, ...,\n",
       "                 -5.49496263e-02, -1.53637631e-02, -7.20476508e-02],\n",
       "                ...,\n",
       "                [-2.25043185e-02,  6.59201816e-02, -1.74533091e-02, ...,\n",
       "                 -3.82866003e-02,  4.96239290e-02,  6.61709011e-02],\n",
       "                [ 4.34375852e-02, -7.79409111e-02,  5.89718148e-02, ...,\n",
       "                  1.81603953e-02, -5.28361797e-02, -4.34807986e-02],\n",
       "                [-2.17706710e-02,  4.33730371e-02, -6.67551458e-02, ...,\n",
       "                 -5.62310964e-02, -5.23839220e-02, -2.04095412e-02]],\n",
       "\n",
       "               [[-3.85628305e-02,  7.86706656e-02, -5.57094514e-02, ...,\n",
       "                  1.44156329e-02,  7.24700019e-02, -2.43778694e-02],\n",
       "                [-4.06642407e-02, -4.60969359e-02, -4.77173179e-02, ...,\n",
       "                  6.34865984e-02,  4.34468351e-02,  1.47883091e-02],\n",
       "                [-5.28217852e-03, -2.53092796e-02, -4.73634014e-03, ...,\n",
       "                  5.53949401e-02,  2.52293628e-02, -1.74834058e-02],\n",
       "                ...,\n",
       "                [-5.73133230e-02, -3.34653771e-03, -4.52707633e-02, ...,\n",
       "                 -3.72699499e-02, -4.87356707e-02, -1.19094895e-02],\n",
       "                [-4.01306413e-02, -7.82515109e-02, -4.57876287e-02, ...,\n",
       "                  1.30437762e-02, -5.87365329e-02,  5.39592393e-02],\n",
       "                [ 3.37451249e-02, -4.94026998e-03, -5.45324944e-02, ...,\n",
       "                 -5.68727683e-03,  6.54212162e-02, -8.82843509e-02]],\n",
       "\n",
       "               [[-5.66718206e-02,  5.92618622e-02,  8.22561514e-03, ...,\n",
       "                 -4.91697937e-02,  7.19519854e-02, -9.84572899e-03],\n",
       "                [ 5.63031547e-02, -2.26709768e-02,  7.70309716e-02, ...,\n",
       "                 -7.58297071e-02,  3.06688598e-05, -7.66935423e-02],\n",
       "                [-4.71370369e-02,  8.26345198e-03, -1.35479569e-02, ...,\n",
       "                  7.02116638e-02, -5.45870699e-03,  6.90048933e-02],\n",
       "                ...,\n",
       "                [ 6.12563789e-02,  1.10345036e-02, -4.48230319e-02, ...,\n",
       "                 -5.10234162e-02,  1.54933967e-02, -3.98078300e-02],\n",
       "                [ 5.16634509e-02,  4.14577350e-02,  1.71268061e-02, ...,\n",
       "                 -7.13671297e-02,  4.79272604e-02, -2.72382963e-02],\n",
       "                [ 7.18142986e-02,  6.08403385e-02, -5.33357412e-02, ...,\n",
       "                 -2.51291115e-02,  9.16521922e-02,  9.76048782e-03]]]],\n",
       "             dtype=float32)                                             ,\n",
       "       array([-6.8568960e-03, -2.3014855e-03, -5.1924959e-03, -4.8575001e-03,\n",
       "               6.1979919e-04,  1.9993109e-05, -1.0992929e-03,  9.7135995e-03,\n",
       "               2.2450858e-03, -7.2495798e-03, -4.6906923e-03, -2.9411118e-03,\n",
       "              -3.7205382e-03,  9.0422295e-03,  2.8364761e-03, -3.9870054e-03,\n",
       "               4.1556562e-04,  2.6039321e-03,  8.6900201e-03, -5.2349446e-03,\n",
       "               2.7123329e-03, -7.1774889e-04, -2.9939337e-04, -4.4666082e-03,\n",
       "              -6.7671086e-03,  5.7771360e-04,  2.6544323e-03,  6.2519135e-03,\n",
       "               3.1863386e-04,  4.7847759e-03, -6.9581377e-03,  5.4643664e-05,\n",
       "              -1.2689639e-03,  6.0706469e-04,  4.9170065e-03, -5.7986081e-03,\n",
       "               2.2466991e-03, -1.7445271e-03, -7.4239098e-05,  6.5783306e-04,\n",
       "              -7.0201075e-03, -3.5846580e-04, -3.1494373e-04,  7.8700501e-03,\n",
       "               7.2995964e-03, -7.9952984e-04, -5.7574008e-03, -3.6414678e-03,\n",
       "              -2.8070230e-03,  9.9171549e-03, -1.0628144e-03, -3.0792414e-03,\n",
       "              -2.4646455e-03,  8.5346084e-03,  8.2847867e-03, -7.0330198e-03,\n",
       "              -2.4943561e-03, -4.1976832e-03, -4.6953089e-03, -4.1709826e-03,\n",
       "              -5.9648152e-03, -3.8822021e-03,  4.3935422e-03, -1.6290293e-03],\n",
       "             dtype=float32)                                                   ,\n",
       "       array([[-0.01927977, -0.03063557,  0.00975168, ...,  0.03095681,\n",
       "               -0.05055512, -0.03229455],\n",
       "              [-0.02437321,  0.00702724,  0.04530511, ...,  0.0259427 ,\n",
       "                0.05203832, -0.04525767],\n",
       "              [-0.0426614 , -0.0682799 ,  0.04258537, ...,  0.06397764,\n",
       "               -0.02849572, -0.03515315],\n",
       "              ...,\n",
       "              [-0.06509591,  0.00777938,  0.06420276, ...,  0.04230881,\n",
       "                0.00990323, -0.04850865],\n",
       "              [ 0.05186648,  0.05837027, -0.00594177, ...,  0.04183413,\n",
       "                0.03129588,  0.00069251],\n",
       "              [ 0.00931903, -0.06839958, -0.03374721, ...,  0.01946587,\n",
       "               -0.06679426,  0.00691725]], dtype=float32)              ,\n",
       "       array([ 0.00078876,  0.00989407, -0.00417032, -0.00863627, -0.0034835 ,\n",
       "              -0.00978405,  0.00659403, -0.00583203, -0.00851086, -0.00365039],\n",
       "             dtype=float32)                                                    ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_default_model(json_model_config, \n",
    "                global_model_weights,\n",
    "                x_train,\n",
    "                y_train,\n",
    "                epochs=10,\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\", \n",
    "                metrics=[\"accuracy\"],\n",
    "                **extra_compiler_arguments):\n",
    "\n",
    "    # import dependencies\n",
    "    from tensorflow import keras\n",
    "\n",
    "    # create the model\n",
    "    model = keras.models.model_from_json(json_model_config)\n",
    "\n",
    "    # compile the model and set weights to the global model\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, **extra_compiler_arguments)\n",
    "    model.set_weights(global_model_weights)\n",
    "\n",
    "    # train the model on the local data and extract the weights\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    model_weights = model.get_weights()\n",
    "\n",
    "    # transform to a numpy array\n",
    "    np_model_weights = np.asarray(model_weights, dtype=object)\n",
    "\n",
    "    return np_model_weights\n",
    "\n",
    "\n",
    "train_default_model(json_config, gm_weights_np, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4873a64e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/2502181789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtrain_default_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgm_weights_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/2502181789.py\u001b[0m in \u001b[0;36mtrain_default_model\u001b[1;34m(json_model_config, global_model_weights, x_train, y_train, epochs, **extra_compiler_arguments)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# compile the model and set weights to the global model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_compiler_arguments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_model_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "def train_default_model(json_model_config, \n",
    "                global_model_weights,\n",
    "                x_train,\n",
    "                y_train,\n",
    "                epochs=10,\n",
    "                **extra_compiler_arguments):\n",
    "\n",
    "    # import dependencies\n",
    "    from tensorflow import keras\n",
    "\n",
    "    # create the model\n",
    "    model = keras.models.model_from_json(json_model_config)\n",
    "\n",
    "    # compile the model and set weights to the global model\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, **extra_compiler_arguments)\n",
    "    model.set_weights(global_model_weights)\n",
    "\n",
    "    # train the model on the local data and extract the weights\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    model_weights = model.get_weights()\n",
    "\n",
    "    # transform to a numpy array\n",
    "    np_model_weights = np.asarray(model_weights, dtype=object)\n",
    "\n",
    "    return np_model_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_default_model(json_config, gm_weights_np, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e660c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate py37\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from funcx.sdk.client import FuncXClient\n",
    "from funcx.sdk.executor import FuncXExecutor\n",
    "\n",
    "# path_dir='/home/pi/datasets', x_train_path=\"mnist_x_train.npy\", y_train_path=\"mnist_y_train.npy\"\n",
    "def get_local_data(x_train_path, y_train_path, path_dir=\".\", preprocess=None, preprocessing_function=None):\n",
    "    '''\n",
    "    Returns (x_train, y_train) given the edge directory and filenames.\n",
    "    \n",
    "    '''\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import collections\n",
    "    \n",
    "    x_train_path_file = os.sep.join([path_dir, x_train_path])\n",
    "    y_train_path_file = os.sep.join([path_dir, y_train_path])\n",
    "\n",
    "    with open(x_train_path_file, 'rb') as f:\n",
    "        x_train = np.load(f)\n",
    "        \n",
    "    with open(y_train_path_file, 'rb') as f:\n",
    "        y_train = np.load(f)\n",
    "\n",
    "    if preprocess:\n",
    "        # check if a valid function was given\n",
    "        if not preprocessing_function or not isinstance(preprocessing_function, collections.Callable):\n",
    "            raise TypeError('preprocessing_function is not a function. Please provide a valid function in your call')\n",
    "        \n",
    "        (x_train, y_train) = preprocessing_function(x_train, y_train)\n",
    "\n",
    "    return (x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "def get_keras_data(keras_dataset, preprocess=True, num_samples=None):\n",
    "    '''\n",
    "    Returns (x_train, y_train) of a chosen built-in Keras dataset.\n",
    "    Options: ['mnist', 'fashion_mnist', 'cifar10', 'cifar100', 'imdb', 'reuters', 'boston_housing']\n",
    "    \n",
    "    '''\n",
    "    from tensorflow import keras\n",
    "    import numpy as np\n",
    "\n",
    "    available_datasets = ['mnist', 'fashion_mnist', 'cifar10', 'cifar100', 'imdb', 'reuters', 'boston_housing']\n",
    "    dataset_mapping= {\n",
    "        'mnist': keras.datasets.mnist,\n",
    "        'fashion_mnist': keras.datasets.fashion_mnist,\n",
    "        'cifar10': keras.datasets.cifar10,\n",
    "        'cifar100': keras.datasets.cifar100,\n",
    "        'imdb': keras.datasets.imdb,\n",
    "        'reuters': keras.datasets.reuters,\n",
    "        'boston_housing': keras.datasets.boston_housing\n",
    "    }\n",
    "    image_datasets = ['mnist', 'fashion_mnist', 'cifar10', 'cifar100']\n",
    "\n",
    "    # check if the dataset exists\n",
    "    if keras_dataset not in available_datasets:\n",
    "        raise Exception(f\"Please select one of the built-in Keras datasets: {available_datasets}\")\n",
    "\n",
    "    else:\n",
    "        (x_train, y_train), _ = dataset_mapping[keras_dataset].load_data()\n",
    "\n",
    "        # take a random set of images\n",
    "        if num_samples:\n",
    "            idx = np.random.choice(np.arange(len(x_train)), num_samples, replace=True)\n",
    "            x_train = x_train[idx]\n",
    "            y_train = y_train[idx]\n",
    "\n",
    "        # do default image processing for built-in Keras images\n",
    "        if preprocess:\n",
    "            if keras_dataset in image_datasets:\n",
    "                # Scale images to the [0, 1] range\n",
    "                x_train = x_train.astype(\"float32\") / 255\n",
    "\n",
    "                # Make sure images have shape (num_samples, x, y, 1) if working with MNIST images\n",
    "                if x_train.shape[-1] not in [1, 3]:\n",
    "                    x_train = np.expand_dims(x_train, -1)\n",
    "\n",
    "                # convert class vectors to binary class matrices\n",
    "                num_classes=10\n",
    "                y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "        return (x_train, y_train)\n",
    "\n",
    "def train_default_model(json_model_config, \n",
    "                global_model_weights,\n",
    "                x_train,\n",
    "                y_train,\n",
    "                epochs=10,\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\", \n",
    "                metrics=[\"accuracy\"],\n",
    "                **extra_compiler_arguments):\n",
    "\n",
    "    # import dependencies\n",
    "    from tensorflow import keras\n",
    "    import numpy as np\n",
    "\n",
    "    # create the model\n",
    "    model = keras.models.model_from_json(json_model_config)\n",
    "\n",
    "    # compile the model and set weights to the global model\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, **extra_compiler_arguments)\n",
    "    model.set_weights(global_model_weights)\n",
    "\n",
    "    # train the model on the local data and extract the weights\n",
    "    model.fit(x_train, y_train, epochs=epochs)\n",
    "    model_weights = model.get_weights()\n",
    "\n",
    "    # transform to a numpy array\n",
    "    np_model_weights = np.asarray(model_weights, dtype=object)\n",
    "\n",
    "    return np_model_weights\n",
    "\n",
    "\n",
    "def create_training_function(train_model=train_default_model, \n",
    "                            data_source: str = \"keras\",\n",
    "                            preprocessing_function=None,\n",
    "                            path_dir='/home/pi/datasets', \n",
    "                            x_train_path=\"mnist_x_train.npy\", \n",
    "                            y_train_path=\"mnist_y_train.npy\", \n",
    "                            preprocess_local=True, \n",
    "                            keras_dataset = \"mnist\", \n",
    "                            preprocess_keras=True, \n",
    "                            loss=\"categorical_crossentropy\",\n",
    "                            optimizer=\"adam\", \n",
    "                            metrics=[\"accuracy\"],\n",
    "                            get_keras_data=get_keras_data,\n",
    "                            get_local_data=get_local_data,\n",
    "                            **kwargs\n",
    "):\n",
    "    \n",
    "    def training_function(json_model_config, \n",
    "                          global_model_weights, \n",
    "                          num_samples=None,\n",
    "                          epochs=10,\n",
    "                          **kwargs\n",
    "):\n",
    "\n",
    "        # import all the dependencies required for funcX functions)\n",
    "        import numpy as np\n",
    "\n",
    "        if data_source == 'local':\n",
    "            (x_train, y_train) = get_local_data(path_dir=path_dir, \n",
    "                          x_train_path=x_train_path, \n",
    "                          y_train_path=y_train_path, \n",
    "                          preprocess=preprocess_local, \n",
    "                          preprocessing_function=preprocessing_function)\n",
    "\n",
    "        elif data_source == 'keras':\n",
    "            (x_train, y_train) = get_keras_data(keras_dataset, \n",
    "                                                preprocess_keras, \n",
    "                                                num_samples)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Please choose one of data sources: ['local', 'keras']\")\n",
    "\n",
    "        # consider switching to args* and kwargs** in case of a custom training function\n",
    "        model_weights = train_model(json_model_config, \n",
    "                                    global_model_weights, \n",
    "                                    x_train, \n",
    "                                    y_train,\n",
    "                                    epochs,\n",
    "                                    loss,\n",
    "                                    optimizer, \n",
    "                                    metrics,\n",
    "                                    **kwargs)\n",
    "\n",
    "        return {\"model_weights\":model_weights, \"samples_count\": x_train.shape[0]}\n",
    "    \n",
    "    return training_function\n",
    "\n",
    "def get_edge_weights(sample_counts):\n",
    "    '''\n",
    "    Returns weights for each model to find the weighted average \n",
    "    '''\n",
    "    total = sum(sample_counts)\n",
    "    fractions = sample_counts/total\n",
    "    return fractions\n",
    "\n",
    "def federated_average(global_model, \n",
    "                      endpoint_ids, \n",
    "                      num_samples=100,\n",
    "                      epochs=10,\n",
    "                      weighted=False,\n",
    "                      train_model=train_default_model, \n",
    "                      data_source: str = \"keras\",\n",
    "                      preprocessing_function=None,\n",
    "                      path_dir='/home/pi/datasets', \n",
    "                      x_train_path=\"mnist_x_train.npy\", \n",
    "                      y_train_path=\"mnist_y_train.npy\", \n",
    "                      preprocess_local=None, \n",
    "                      keras_dataset = \"mnist\", \n",
    "                      preprocess_keras=True, \n",
    "                      loss=\"categorical_crossentropy\",\n",
    "                      optimizer=\"adam\", \n",
    "                      metrics=[\"accuracy\"],\n",
    "                      **kwargs):\n",
    "\n",
    "    fx = FuncXExecutor(FuncXClient())\n",
    "\n",
    "    # get the model's architecture and weights\n",
    "    json_config = global_model.to_json()\n",
    "    gm_weights = global_model.get_weights()\n",
    "    gm_weights_np = np.asarray(gm_weights, dtype=object)\n",
    "\n",
    "    # compile the training function\n",
    "    training_function = create_training_function(train_model=train_model, \n",
    "                                                data_source = data_source,\n",
    "                                                path_dir=path_dir, \n",
    "                                                x_train_path=x_train_path, \n",
    "                                                y_train_path=y_train_path, \n",
    "                                                preprocess_local=preprocess_local, \n",
    "                                                preprocessing_function=preprocessing_function,\n",
    "                                                keras_dataset = keras_dataset, \n",
    "                                                preprocess_keras=preprocess_keras, \n",
    "                                                loss=loss,\n",
    "                                                optimizer=optimizer, \n",
    "                                                metrics=metrics)\n",
    "    \n",
    "    # train the MNIST model on each of the endpoints and return the result, sending the global weights to each edge\n",
    "    tasks = []\n",
    "    for e in endpoint_ids:\n",
    "        tasks.append(fx.submit(training_function, \n",
    "                                json_model_config=json_config, \n",
    "                                global_model_weights=gm_weights_np, \n",
    "                                num_samples=num_samples,\n",
    "                                epochs=epochs,\n",
    "                                endpoint_id=e))\n",
    "    \n",
    "    # extract weights from each edge model\n",
    "    model_weights = [t.result()[\"model_weights\"] for t in tasks]\n",
    "    \n",
    "    if weighted:\n",
    "        # get the weights\n",
    "        sample_counts = np.array([t.result()[\"samples_count\"] for t in tasks])\n",
    "        edge_weights = get_edge_weights(sample_counts)\n",
    "        \n",
    "        print(f\"Model Weights: {edge_weights}\")\n",
    "        # find weighted average\n",
    "        average_weights = np.average(model_weights, weights=edge_weights, axis=0)\n",
    "        \n",
    "    else:\n",
    "        # simple average of the weights\n",
    "        average_weights = np.mean(model_weights, axis=0)\n",
    "    \n",
    "    # assign the weights to the global_model\n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    print('Trained Federated Model')\n",
    "\n",
    "    return global_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "216992c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model's architecture and weights\n",
    "json_config = global_model.to_json()\n",
    "gm_weights = global_model.get_weights()\n",
    "gm_weights_np = np.asarray(gm_weights, dtype=object)\n",
    "\n",
    "# compile the training function\n",
    "training_function = create_training_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e9f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=100,\n",
    "epochs=10\n",
    "weighted=False\n",
    "train_model=train_default_model,\n",
    "data_source=\"keras\"\n",
    "preprocessing_function=None\n",
    "path_dir='/home/pi/datasets'\n",
    "x_train_path=\"mnist_x_train.npy\"\n",
    "y_train_path=\"mnist_y_train.npy\"\n",
    "preprocess_local=None\n",
    "keras_dataset = \"mnist\"\n",
    "preprocess_keras=True\n",
    "loss=\"categorical_crossentropy\"\n",
    "optimizer=\"adam\"\n",
    "metrics=[\"accuracy\"]\n",
    "\n",
    "training_function = create_training_function(train_model=train_model, \n",
    "                                            data_source = data_source,\n",
    "                                            path_dir=path_dir, \n",
    "                                            x_train_path=x_train_path, \n",
    "                                            y_train_path=y_train_path, \n",
    "                                            preprocess_local=preprocess_local, \n",
    "                                            preprocessing_function=preprocessing_function,\n",
    "                                            keras_dataset = keras_dataset, \n",
    "                                            preprocess_keras=preprocess_keras, \n",
    "                                            loss=loss,\n",
    "                                            optimizer=optimizer, \n",
    "                                            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fba7cb38",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/3139108736.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_model_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_model_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgm_weights_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19800/3471783320.py\u001b[0m in \u001b[0;36mtraining_function\u001b[1;34m(json_model_config, global_model_weights, num_samples, epochs, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                                     \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                                     \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                                     **kwargs)\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"model_weights\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"samples_count\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "training_function(json_model_config=json_config, global_model_weights=gm_weights_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d984b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "endpoint_ids = ['00929e1a-ccc5-40be-8b04-c171f132f7b2', '11983ca1-2d45-40d1-b5a2-8736b3544dea']\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "global_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "global_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "051450b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(num_samples=1000):\n",
    "    from tensorflow import keras\n",
    "    num_classes = 10\n",
    "    _, (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    \n",
    "    idx = np.random.choice(np.arange(len(x_test)), num_samples, replace=True)\n",
    "    x_test = x_test[idx]\n",
    "    y_test = y_test[idx]\n",
    "    \n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return (x_test, y_test)\n",
    "\n",
    "def eval_model(m, x, y):\n",
    "    ''' evaluate model on dataset x,y'''\n",
    "    score = m.evaluate(x, y, verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "    \n",
    "x_test, y_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "674e173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_train, y_train, num_samples=100):\n",
    "    from tensorflow import keras\n",
    "    import numpy as np\n",
    "\n",
    "    num_classes = 10\n",
    "\n",
    "    # take a random set of images\n",
    "    idx = np.random.choice(np.arange(len(x_train)), num_samples, replace=True)\n",
    "    x_train = x_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(x_train.shape[0], \"train samples\")\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "    return (x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    federated_average(global_model=global_model, \n",
    "                  endpoint_ids=endpoint_ids,\n",
    "                  data_source=\"local\",\n",
    "                  path_dir='/home/pi/datasets', \n",
    "                  x_train_path=\"mnist_x_train.npy\", \n",
    "                  y_train_path=\"mnist_y_train.npy\", \n",
    "                  preprocess_local=True,\n",
    "                  preprocessing_function=preprocess_data)\n",
    "    eval_model(global_model, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
